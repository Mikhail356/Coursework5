# Методы сбора данных
Так как написание своего собственного поискового паука не является задачей этой работы, то используется паук широкого назначения от некоммерческой организации CommonCrawl [@YouReReady]. Он обходит весь Интернет, который позволяет себя индексировать, примерно раз в месяц и загружает результаты на свои коллекции. Потом передает URL на них в открытый доступ. Он был выбран так как очень часто новостные страницы используют скриптовые языки на своих сайтах. А это значит что их очень сложно обходить и выгружать с них сами тексты новостей. Также на новостных страницах часто бывают дополнительные новости бегущей строкой, реклама по сторонам от текста или невидимые обычному посетителю сайта элементы регистрации. Также в данной работе не критична регулярность обновления коллекций новостей в 1 месяц.

CommonCrawl позволяет искать страницы по определенным доменам и URL. Так, вводя в специальном интерфейсе домен $\textquote{.ru}$ вам будут даны ссылки на скачивание всех сайтов у которых доменом является $\textquote{.ru}$. Или, например, введя в нем же $\textquote{https://www.kp.ru/}$ вы получите ссылки на архивы для скачивания всей информации находящейся на этом сайте. Также можно указывать метаинформацию (например искать только страницы у которых в структуре хранения текстов в коллекции CommonCrawl указано $\textquote{rus}$), тем самым сужая область поиска.



